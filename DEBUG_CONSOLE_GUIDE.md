# Debug Console Guide - Chatbot API Key Usage

## What You'll See in the Console

When you make requests to the chatbot, you'll now see detailed debug output in your server console (where `npm run dev` is running).

### Example Console Output:

```
ğŸŒ [2024-12-21T13:20:00.000Z] POST /api/chatbot/message

ğŸ“¨ [REQUEST] New Chatbot Message
   Request ID: abc123
   Timestamp: 2024-12-21T13:20:00.000Z
   IP: ::1
   ğŸ“ Message: "What is 2+2?"
   ğŸ’¬ History Length: 0 messages
   ğŸ”„ Processing request...

ğŸ¤– [CHATBOT] Starting OpenAI API Call
   âœ… API Key: sk-proj-rNHC30Gz... (164 chars)
   Model: gpt-3.5-turbo
   Temperature: 0.7
   Max Tokens: 1000
   User Message: "What is 2+2?"
   Conversation History: 1 messages
   ğŸ“¡ Calling OpenAI API...
   âœ… OpenAI API Response Received
   â±ï¸  Response Time: 1143ms
   ğŸ“Š Model Used: gpt-3.5-turbo-0125
   ğŸ’¬ Response: "The answer is 4."
   ğŸ¯ Token Usage:
      - Prompt Tokens: 257
      - Completion Tokens: 15
      - Total Tokens: 272
   âœ… Request completed successfully

   âœ… [RESPONSE] Request abc123 completed successfully
   ğŸ“¤ Sending response to client
```

## What Each Section Shows:

### 1. **Request Information** ğŸ“¨
- Request ID (unique identifier)
- Timestamp
- Client IP address
- User message preview
- Conversation history length

### 2. **API Key Status** ğŸ”‘
- âœ… Shows API key preview (first 15 chars)
- Shows total key length
- Confirms key is loaded

### 3. **OpenAI Configuration** âš™ï¸
- Model being used
- Temperature setting
- Max tokens limit

### 4. **API Call Progress** ğŸ“¡
- When API call starts
- Response time (network latency)
- Model actually used by OpenAI

### 5. **Token Usage** ğŸ¯
- Prompt tokens (input)
- Completion tokens (output)
- Total tokens (cost calculation)

### 6. **Response Details** ğŸ’¬
- Preview of AI response
- Success/failure status

## How to View Debug Logs:

### Method 1: Terminal/Console
1. Open the terminal where you ran `npm run dev`
2. Keep it visible while testing
3. Make requests from frontend or API
4. Watch the logs appear in real-time

### Method 2: Test via API
```bash
curl -X POST http://localhost:5000/api/chatbot/message \
  -H "Content-Type: application/json" \
  -d '{"message":"Hello","conversationHistory":[]}'
```

Then check your server console for the debug output.

### Method 3: Test via Frontend
1. Open http://localhost:3000
2. Click the chat button
3. Send a message
4. Watch the server console for logs

## Error Debugging:

If there's an error, you'll see:

```
âŒ [CHATBOT] OpenAI API Error:
   Error Type: APIError
   Error Message: Invalid API key
   ğŸ”‘ API Key Issue: Invalid or unauthorized
   ğŸ’¡ Check: Is your API key correct in .env file?
```

## What to Look For:

âœ… **Good Signs:**
- API key shows with preview
- Response time: 500ms - 3000ms
- Token usage reported
- Model name: `gpt-3.5-turbo-0125` or similar

âŒ **Warning Signs:**
- "API Key: NOT SET"
- Instant response (< 50ms) - might be cached
- No token usage
- Error messages

## Tips:

1. **Keep Console Visible**: Keep your server terminal open while testing
2. **Watch for Errors**: Red error messages will show API issues
3. **Monitor Token Usage**: Track costs by watching token counts
4. **Check Response Times**: Slow responses indicate network issues
5. **Verify API Key**: First log shows if key is loaded correctly

## Example: Full Request Flow

```
1. Request arrives â†’ ğŸ“¨ [REQUEST] appears
2. API key checked â†’ âœ… API Key: sk-proj-... shown
3. OpenAI called â†’ ğŸ“¡ Calling OpenAI API...
4. Response received â†’ âœ… OpenAI API Response Received
5. Tokens counted â†’ ğŸ¯ Token Usage shown
6. Response sent â†’ âœ… [RESPONSE] completed
```

---

**Now restart your server and watch the console!** ğŸ‰




